\section{Ranking in the Presence of Missing Data}

\subsection{Introduction}

In the previous chapter we considered pairwise comparisons between adjectives only, when there is no data supporting the pairwise comparison, we answer with ``do not know."  We would like to determine some way of knowing. Towards this end, in this chapter we ask if it is possible to compare the two adjectives by \textit{not} comparing them. In other words, suppose we have a data set where we do not observe any pairwise comparisons between adjectives in the annotated sets, how well can we perform? We present two \textit{heuristics} towards this question: neighborhood heuristic and shortest path heuristic. But first we need to construct the appropriate test set for our task.


\subsection{Test Set}

Since we are only interested in attaining a pairwise accuracy for word pairs for which no data exists, we construct a new test set using annotated gold set in the following manner: for every pair of words in each cluster where no data exist, we create a new cluster with just these two words. For example, if in a cluster: ``ok $<$ good $<$ great $<$ excellent" there are no data between ``ok" and ``great", and ``good" and ``excellent", then we form two clusters in the new pairwise set ``ok $<$ great" and ``good $<$ excellent". Furthermore, since we have three graphs: one with only edges from PPDB, one with only edges from the N-Gram set, and their combination, we construct the aforementioned pairs for each graph. The number of pairs for each set of pairs, for each graph, is listed below. 


\begin{table}
\small
\centering
\begin{tabular}{|l|c|c|c|}
	% 
	\hline 
	& \multicolumn{1}{c|}{Mohit} 
	& \multicolumn{1}{c|}{Turk} 
	& \multicolumn{1}{c|}{BCS} \\
	\hline 
	% 
	N-gram          & 550 & 586 & 556 \\
	PPDB            & 750 & 182 & 294 \\
	PPDB + N-gram   & 408 & 170 & 290 \\
	% 
	\hline
\end{tabular}
\caption{\label{font-table} Number of pairs where no data exist in the graph for each gold set. }
\end{table}

Recall in the previous chapter we aimed for $\frac{1}{log(n)}$ pairwise accuracy, below is a table that computes this accuracy for each set. In the rest of this chapter unless otherwise noted, when we say the ``test set", we mean the set of adjective pairs for which no data exists.  

\begin{table}
\small
\centering
\begin{tabular}{|l|c|c|c|}
	% 
	\hline 
	& \multicolumn{1}{c|}{Mohit} 
	& \multicolumn{1}{c|}{Turk} 
	& \multicolumn{1}{c|}{BCS} \\
	\hline 
	% 
	N-gram          & 84\% & 84\% & 84\% \\
	PPDB            & 85\% & 85\% & 82\% \\
	PPDB + N-gram   & 83\% & 80\% & 82\% \\
	% 
	\hline
\end{tabular}
\caption{\label{font-table} The table of ``reasonable probability" hurdles we must cross. }
\end{table}



\subsection{Neighborhood Heuristic Formulation}

Similar to the road map laid out in the problem formulation chapter, we suppose each edge in the graph is placed independently, and similar to the previous chapter we estimate $\Prob[ s < t ]$ with pointwise estimation, without considering the comparisons between $s$ and $t$. In the simplest case we answer with $\frac{1}{2}$ again, this is exactly the ``random" baseline we witnessed. An immediate improvement is to estimate this probability using local connectivity of each adjectives. 

Suppose we wish to compare vertices $s$ and $t$, then for a vertex $s$ we can form the neighbor $\N$ of $s$ without $t$ with:

	\[
		\N_{s/t} = \{ x : x \in \N_{s/t}\}.
	\]

Note if $t$ is not in the neighborhood of $s$ then $\N_s = \N_{s/t}.$ Now we make the simplifying assumption that all vertices in $\N_{s/t}$ are the same. Again we let $<$ be a Bernoulli variable with parameter $p$, since all vertices are the same, so we have for $\pmb{\Omega} = \{<,>\}$ and the frequencies of $<$ and $>$ are estimated from the set: $\N_{s/t}$:
	\[
		\Prob_{\pmb{\Omega}}[s < t] = \frac{\{ s < x \in \N_{s/t}\}}{|\N_{s/t}|},
	\]

and $\Prob_{\pmb{\Omega}}[t < s] = 1 - \Prob_{\pmb{\Omega}}[s < t].$ But could also determine $\Prob[t < s]$ by examining $t$. That is we can form $\N_{t/s}$ and for $\pmb{\Omega} = \{<',>'\}$ defined where the frequencies are estimated from $\N_{t/s}$:
	\[
		\Prob_{\pmb{\Omega}'}[t < s] = \frac{\{ t < x \in \N_{t/s}\}}{|\N_{t/s}|},
	\]
where $\Prob_{\pmb{\Omega}'}[s < t] = 1 - \Prob_{\pmb{\Omega}'}[t < s].$ These definitions are simple but they create a very pernicious problem: the probabilities do not sum to one in every case. This is not surprising since the distributions are placed over outcomes of $<$ over different sets. If our goal is to toss a coin and place edges between vertices, then what we have defined cannot be used. One way forward is to make another simplifying assumption, all vertices in neighbor of $t$ and neighbors of $s$ are the same, we call this vertex $z$. Now we have four possibilities, $s < z < t$, $s > z > t$, $s < z > t$, and $s > z < t$. In the first two cases it is clear that either $s < t$ or $s > t$, in the next two it is not clear, so we do not consider the next two cases when computing our probability; this is in the spirit of our $argmax$ function: contradictory results are not considered. There is a natural interpretation to this formulation: we are using intermediate vertices between $s$ and $t$ to rank them, assuming all vertices are the same. All in all, our final data set is $\N_{st} = \N_{s/t} \cup \N_{t/s}$, and: 
	\[
		\Prob[s < t ] = \frac{| \{s < z < t \in \N_{st}\}|}{|\{s < z < t \in \N_{st}\}| + |\{s > z > t \in \N_{st}\}|}.
	\]

\begin{remark}
If $| \N_{st} | = 1$ so that we have a single vertex $r$ with edges between $s$ and $r$ and $t$ and $r$, then the formulation above is using an intermediate word to rank the two words given. Note in this case we could also have two cases where they are both stronger than $r$ or weaker than $r$, there is no information gained from these cases unless we examine $r$ itself, as a baseline we ignore these cases.
\end{remark}

\begin{remark}
If $\N_{s/t} \cup \N_{t/s} = \N_{s/t} \cap \N_{t/s}$, then the two words are in a community for a loose definition of community, so we are using all \textit{informative} intermediary paths in the community to rank the two adjectives.
\end{remark}

\begin{remark}
If $\N_{s/t} \cap \N_{t/s} = \emptyset$, then we are assuming although they do not share neighbors, the vertices in their neighbors are ``similar" in strength, again for a very loose definition of strength. 
\end{remark}

\subsection{Shortest Path Heuristic Formulation}

The previous heuristic does a breadth first search of depth one and attempt to rank $s$ and $t$ using all of their neighbors. Now we consider the \textit{smallest} set of neighbors possible: this is the shortest path between $s$ and $t$. Suppose we observe the shortest path from $s$ to $t$: $\pmb{P}_s[t] = (s, s_1,\ldots,s_n, t)$, and similarly from $t$ to $s$: $\pmb{P}_t[s] = (t, t_1,\ldots,t_m, s)$, then we can express $\Prob[s < t]$ by tossing coins along these two paths.

First we need to be very clear on what the set of events we are considering, and how we need to reduce this set to fit our problem. Suppose we observe $\pmb{P}_s[t] = (s, s_1, \ldots, s_n, t)$, then there are $n+2$ vertices along this path, and $n+1$ edges. Thus there are $2^{n+1}$ possible placement of edges between these vertices, the enumeration of all these placements \textit{could be} the set of our elementary events $\pmb{\Omega}$. For example, the following three paths are drawn from $\pmb{\Omega}$:

\begin{enumerate}
	\item $s < s_1 < \ldots < s_n < t$
	\item $s > s_1 > \ldots > s_n > t$
	\item $s > s_1 < s_2 > s_3 \ldots > s_n < t$.
\end{enumerate}

From the first statement we can conclude $s < t$, from the second we see $s > t$. In the third path, no conclusion can be drawn. In fact, in all but two paths, there are either contradictions or inconclusive evidence based on path alone. We discard these $2^{n+1}-2$ paths and our reduced event space is just $\pmb{\Omega} = \{s < s_1 < \ldots < t, s > s_1 > \ldots > t\}.$

\begin{definition}
We say $s$ is less intense than $t$ through $\pmb{P}_s[t]$, written $s <_{\pmb{P}_s} t$, if we observe the path $(s, s_1, \ldots, s_n, t)$ implying that:


	\[
		s < s_1 < \ldots < s_n < t.
	\]
Assuming the edges between all vertices are placed independently , then the probability of that $s <_{\pmb{P}_s} t$ is exactly the probability of this path (properly normalized of course):
	\[
		\Prob[s <_{\pmb{P}_s} t] = \frac{\Prob[s < s_1] \Prob[s_n < t] \prod_{i \in \{1,\ldots,n\}, i < j} \Prob[s_i < s_j]}{\Prob[s <_{\pmb{P}_s} t] + \Prob[t <_{\pmb{P}_s} s]},
	\]
where:
	\[
		\Prob[t <_{\pmb{P}_s} s] = \frac{\Prob[s > s_1] \Prob[s_n > t] \prod_{i \in \{1,\ldots,n\}, i < j} \Prob[s_i > s_j]}{\Prob[s <_{\pmb{P}_s} t] + \Prob[t <_{\pmb{P}_s} s]}.
	\]

Finally for each $s_i$ and $s_j$, we have:
	\[
		\Prob[ s_i < s_j ] = \frac{|\{ s_i < s_j \in \pmb{S}_{ij} \}|}{|\pmb{S}_{ij}|},
	\]
where $\pmb{S}_{ij}$ is the set of edges between $s_i$ and $s_j$: 
	\[
		\pmb{S}_{ij} = \{ s_i < s_j, s_i < s_j, \ldots, s_i > s_j \ldots \}.
	\]

Note since there exists a path through all $s_i$'s, by construction $\pmb{S}_{ij} \neq \emptyset$ for every $i$ and $j$. 
\end{definition}

Next we can define a similar measure for $\pmb{P}_t[s]$. But since the shortest path from $s$ to $t$ are not guaranteed to pass through the same vertices as from $t$ to $s$, $\Prob[s <_{\pmb{P}_s} t] \neq \Prob[ s <_{\pmb{P}_t} t]$, again we need to combine the two measures. The simplest way forward might be to define $s$ is less than $t$ if and only if the two measures agree, and similarly for $s$ greater than $t$. Indeed this is the definition we choose.

\begin{definition}

The vertex $s$ is less intense than $t$ under the paths enumerated by $\pmb{P}_s[t]$ and $\pmb{P}_t[s]$, written $s <_{\pmb{P}_{st}} t$, if and only if $s <_{\pmb{P}_s} t$ and $s <_{\pmb{P}_t} t$. Furthemore, $t <_{\pmb{P}_{st}} s$ if and only if $t <_{\pmb{P}_s} s$ and $t <_{\pmb{P}_t} s$. If however we observe $t <_{\pmb{P}_s} s$ and $s <_{\pmb{P}_t} t$ or $s <_{\pmb{P}_s} t$ and $t <_{\pmb{P}_t} s$, then the results are discarded. Now if we let $p = \Prob[s <_{\pmb{P}_s} t]$ and $q = \Prob[s <_{\pmb{P}_t} t]$, by the law of conditional probability we have:
	\begin{align*}
		\Prob[s <_{\pmb{P}_{st}} t] = \frac{pq}{pq + (1-p)(1-q)}, 
	\end{align*}
and $\Prob[t <_{\pmb{P}_{st}} s] = 1 - \Prob[s <_{\pmb{P}_{st}} t]$.
\end{definition}

\begin{remark}
	This measure is biased against longer paths, for example if length $\pmb{P}_t[s] \neq $ length of $\pmb{P}_t[s]$. But by definition this cannot be an issue since in the numerator we have $pq$.
\end{remark}

\begin{remark}
	A demanding reader might think discarding all $2^{n+1} - 2$ events is intellectually lazy, for example if we only observe one sign is flipped in a run of all $<$'s, can't we say something about the relationship between $s$ and $t$? The answer is no unless we consider vertices for which the sign has been flipped, and their neighbors. These are not the kind of questions we can ask with the elementary game of coin tosses we have committed to play. Later in the thesis we will experiment with measures using more advanced tools for just this question.
\end{remark}

\begin{remark}
	In practice there is often no path between two vertices, in this case we define the probability that $s < t$ to be $\frac{1}{2}$.
\end{remark}

\begin{remark}
 	Once again we must contend with implementation issues. In Python's networkx package, if the two vertices $s$ and $t$ are neighbors, then the shortest path is simply from $s$ to $t$, and so far as I know there is no way to output the next shortest path unless we remove all edges between $s$ and $t$. Since we are only interested in evaluating how well the algorithm does in the case where there is no direct path among $s$ and $t$, if there is a direct path we output $\Prob[ s < t ] = \frac{1}{2}$ by fiat. This way our baseline is not contaminated by information from direct comparisons.
\end{remark}

\begin{remark}
	The remark above is important because if there is a direct path between $s$ and $t$, so that $\Prob[s <_{\pmb{P}_s} t] = \Prob[s <_{\pmb{P}_t} t] = \Prob[s < t] = p$, then we have:
		\[
			\frac{pq}{pq + (1-p)(1-q)} = \frac{p^2}{p^2 + (1-p)^2},
		\]
	which is a quadratic function in $p$ centered at $(\frac{1}{2}, \frac{1}{2})$. That is to say if $p = \frac{1}{2}$, then our expression is an unbiased estimate of $p$, if $p > \frac{1}{2}$ our estimate is larger than $p$, for $p < \frac{1}{2}$ this estimate is smaller than $p$. Clearly for $p$ equals to one or zero, it is unbiased. Overall, our estimate has a strong ``overconfident" bias when $s$ and $t$ are neighbors.
\end{remark}

\begin{remark}
	Note although we are using the ``less than" sign when denoting $s <_{\pmb{P}_{st}} t$, it is technically not proper ordering. For example if we have $s <_{\pmb{P}_{st}} t$ and $t <_{\pmb{P}_{st}} r$, we do not necessarily have $s <_{\pmb{P}_{st}} r$. In fact any time we estimate the ordering from neighboring vertices, transitivity is lost.
\end{remark}



\subsection{Results}

All results are presented in table two through four below. First we direct our attention to the ``uniform" baseline, recall for each pair of words we have $\Prob[s < t] = \frac{1}{2}$. Note the pairwise accuracies are slightly below 50\% for Mohit's set due to the natural bias from reverse sorting, again this effect is most apparent on the base-comparative-superlative set.

Now we direct our attention two table 3, and immediately observe that it only improves the baseline slightly, with the notable exception of the Turk set on the N-gram data, where we achieved $66\%$ pairwise accuracy. Finally on the short-path heuristic, we see marginal increase in performance, again with the exception of Mohit's test set on the PPDB and Ngram data set. 

All in all, none of the measures passed the baseline we laid out, therefore they are all ``reasonably" bad and thus do no warrant further inspection.


\begin{table}
\small
\centering
\begin{tabular}{|l|cc|cc|cc|}
	% 
	\hline 
	& \multicolumn{2}{c|}{N-gram no data} 
	& \multicolumn{2}{c|}{PPDB no data} 
	& \multicolumn{2}{c|}{PPDB + N-gram no data} \\
	\hline 
	\bf Test set
	& \bf Pairwise & \bf Avg. $\tau$  
	& \bf Pairwise & \bf Avg. $\tau$  
	& \bf Pairwise & \bf Avg. $\tau$  \\ 
	\hline
	% 
	Mohit & 47.0\% & -0.05  & 48.0\% & -0.03 & 48.0\% & -0.04 \\
	Turk  & 40.0\% & -0.19  & 37.0\% & -0.25 & 41.0\% & -0.18 \\
	BCS   & 14.0\% & -0.73  & 15.0\% & -0.70 & 15.0\% & -0.70 \\
	% 
	\hline
\end{tabular}
\caption{\label{font-table} Results across all datasets for uniform baseline. Note since $|\tau|$ will be $1.0$ for all test sets, it is not reported. }
\end{table}

\begin{table}
\small
\centering
\begin{tabular}{|l|cc|cc|cc|}
	% 
	\hline 
	& \multicolumn{2}{c|}{N-gram} 
	& \multicolumn{2}{c|}{PPDB} 
	& \multicolumn{2}{c|}{PPDB + N-gram} \\
	\hline 
	\bf Test set
	& \bf Pairwise & \bf Avg. $\tau$  
	& \bf Pairwise & \bf Avg. $\tau$  
	& \bf Pairwise & \bf Avg. $\tau$  \\ 
	\hline
	% 
	Mohit & 61.0\% & 0.21 & 51.0\% & 0.02  & 62.0\% & 0.24 \\
	Turk  & 66.0\% & 0.31 & 56.0\% & 0.12  & 60.0\% & 0.20 \\
	BCS   & 55.0\% & 0.11 & 50.0\% & -0.01 & 59.0\% & 0.17 \\
	% 
	\hline
\end{tabular}
\caption{\label{font-table} Results across all datasets for neighborhood heuristic. }
\end{table}


\begin{table}
\small
\centering
\begin{tabular}{|l|cc|cc|cc|}
	% 
	\hline 
	& \multicolumn{2}{c|}{N-gram} 
	& \multicolumn{2}{c|}{PPDB} 
	& \multicolumn{2}{c|}{PPDB + N-gram} \\
	\hline 
	\bf Test set
	& \bf Pairwise & \bf Avg. $\tau$  
	& \bf Pairwise & \bf Avg. $\tau$  
	& \bf Pairwise & \bf Avg. $\tau$  \\ 
	\hline
	% 
	Mohit & 57.0\% & 0.14  & 50.0\% & -0.01 & 68.0\% & 0.35 \\
	Turk  & 44.0\% & -0.13 & 56.0\% & 0.13  & 51.0\% & 0.01 \\
	BCS   & 27.0\% & -0.47 & 56.0\% & 0.13  & 65.0\% & 0.30 \\
	% 
	\hline
\end{tabular}
\caption{\label{font-table} Results across all datasets for shortest path heuristic.}
\end{table}



