\section{Baseline Using Shortest Path}

\subsection{Introduction}

Since the measure we constructed in the previous chapter peformed poorly, we need to spend this chapter constructing a new measure. Again we are only interested in measuring how well this measure performs, so similar to the previous attempt we do not consider direct comparisons between $s$ and $t$ even if data exists. 

\subsection{Problem Formulation}

In the previous chapter we witnessed that observing all neighbors of $s$ and $t$ introduced confusion, in this chapter we will only consider the \textit{smallest} set of neighbors possible: this is the shortest path between $s$ and $t$. Suppose we observe the shortest path from $s$ to $t$: $\pmb{P}_s[t] = (s, s_1,\ldots,s_n, t)$, and similarly from $t$ to $s$: $\pmb{P}_t[s] = (t, t_1,\ldots,t_m, s)$, then we can express $\Prob[s < t]$ by tossing coins along these two paths.

First we need to be very clear on what the set of events we are considering, and how we need to reduce this set to fit our problem. Suppose we observe $\pmb{P}_s[t] = (s, s_1, \ldots, s_n, t)$, then there are $n+2$ vertices along this path, and $n+1$ edges. Thus there are $2^{n+1}$ possible placement of edges between these vertices, the enumeration of all these placements \textit{could be} the set of our elementary events $\pmb{\Omega}$. For example, the following three paths are drawn from $\pmb{\Omega}$:
\begin{enumerate}
	\item $s < s_1 < \ldots < s_n < t$
	\item $s > s_1 > \ldots > s_n > t$
	\item $s > s_1 < s_2 > s_3 \ldots > s_n < t$.
\end{enumerate}

From the first statement we can conclude $s < t$, from the second we see $s > t$. In the third path, no conclusion can be drawn. In fact, in all but two paths, there are either contradictions or inconclusive evidence based on path alone. We discard these $2^{n+1}-2$ paths and our reduced event space is just $\pmb{\Omega} = \{s < s_1 < \ldots < t, s > s_1 > \ldots > t\}.$

% However similar to the attitude we presented in the problem formulation chapter, we discard all 

\begin{definition}
We say $s$ is less intense than $t$ through $\pmb{P}_s[t]$, written $s <_{\pmb{P}_s} t$, if we observe the path $(s, s_1, \ldots, s_n, t)$ implying that:


	\[
		s < s_1 < \ldots < s_n < t.
	\]
Assuming the edges between all vertices are placed independently , then the probability of that $s <_{\pmb{P}_s} t$ is exactly the probability of this path (properly normalized of course):
	\[
		\Prob[s <_{\pmb{P}_s} t] = \frac{\Prob[s < s_1] \Prob[s_n < t] \prod_{i \in \{1,\ldots,n\}, i < j} \Prob[s_i < s_j]}{\Prob[s <_{\pmb{P}_s} t] + \Prob[t <_{\pmb{P}_s} s]},
	\]
where:
	\[
		\Prob[t <_{\pmb{P}_s} s] = \frac{\Prob[s > s_1] \Prob[s_n > t] \prod_{i \in \{1,\ldots,n\}, i < j} \Prob[s_i > s_j]}{\Prob[s <_{\pmb{P}_s} t] + \Prob[t <_{\pmb{P}_s} s]}.
	\]

Finally for each $s_i$ and $s_j$, we have:
	\[
		\Prob[ s_i < s_j ] = \frac{|\{ s_i < s_j \in \pmb{S}_{ij} \}|}{|\pmb{S}_{ij}|},
	\]
where $\pmb{S}_{ij}$ is the set of edges between $s_i$ and $s_j$: 
	\[
		\pmb{S}_{ij} = \{ s_i < s_j, s_i < s_j, \ldots, s_i > s_j \ldots \}.
	\]

Note since there exists a path through all $s_i$'s, by construction $\pmb{S}_{ij} \neq \emptyset$ for every $i$ and $j$. 
\end{definition}

Next we can define a similar measure for $\pmb{P}_t[s]$. But since the shortest path from $s$ to $t$ are not guaranteed to pass through the same vertices as from $t$ to $s$, $\Prob[s <_{\pmb{P}_s} t] \neq \Prob[ s <_{\pmb{P}_t} t]$, again we need to combine the two measures. The simplest way forward might be to define $s$ is less than $t$ if and only if the two measures agree, and similarly for $s$ greater than $t$. Indeed this is the definition we choose.

\begin{definition}

The vertex $s$ is less intense than $t$ under the paths enumerated by $\pmb{P}_s[t]$ and $\pmb{P}_t[s]$, written $s <_{\pmb{P}_{st}} t$, if and only if $s <_{\pmb{P}_s} t$ and $s <_{\pmb{P}_t} t$. Furthemore, $t <_{\pmb{P}_{st}} s$ if and only if $t <_{\pmb{P}_s} s$ and $t <_{\pmb{P}_t} s$. If however we observe $t <_{\pmb{P}_s} s$ and $s <_{\pmb{P}_t} t$ or $s <_{\pmb{P}_s} t$ and $t <_{\pmb{P}_t} s$, then the results are discarded. Now if we let $p = \Prob[s <_{\pmb{P}_s} t]$ and $q = \Prob[s <_{\pmb{P}_t} t]$, by the law of conditional probability we have:
	\begin{align*}
		\Prob[s <_{\pmb{P}_{st}} t] = \frac{pq}{pq + (1-p)(1-q)}, 
	\end{align*}
and $\Prob[t <_{\pmb{P}_{st}} s] = 1 - \Prob[s <_{\pmb{P}_{st}} t]$.
\end{definition}

\begin{remark}
	This measure is biased against longer paths, for example if length $\pmb{P}_t[s] \neq $ length of $\pmb{P}_t[s]$. But by definition this cannot be an issue since in the numerator we have $pq$.
\end{remark}

\begin{remark}
	A demanding reader might think discarding all $2^{n+1} - 2$ events is intellectually lazy, for example if we only observe one sign is flipped in a run of all $<$'s, can't we say something about the relationship between $s$ and $t$? The answer is no unless we consider vertices for which the sign has been flipped, and their neighbors. These are not the kind of questions we can ask with the elementary game of coin tosses we have committed to play. Later in the thesis we will experiment with measures using more advanced tools for just this question.
\end{remark}

\begin{remark}
	In practice there is often no path between two vertices, in this case we define the probability that $s < t$ to be $\frac{1}{2}$.
\end{remark}

\begin{remark}
 	Once again we must contend with implementation issues. In Python's networkx package, if the two vertices $s$ and $t$ are neighbors, then the shortest path is simply from $s$ to $t$, and so far as I know there is no way to output the next shortest path unless we remove all edges between $s$ and $t$. Since we are only interested in evaluating how well the algorithm does in the case where there is no direct path among $s$ and $t$, if there is a direct path we output $\Prob[ s < t ] = \frac{1}{2}$ by fiat. This way our baseline is not contaminated by information from direct comparisons.
\end{remark}

\begin{remark}
	The remark above is important because if there is a direct path between $s$ and $t$, so that $\Prob[s <_{\pmb{P}_s} t] = \Prob[s <_{\pmb{P}_t} t] = \Prob[s < t] = p$, then we have:
		\[
			\frac{pq}{pq + (1-p)(1-q)} = \frac{p^2}{p^2 + (1-p)^2},
		\]
	which is a quadratic function in $p$ centered at $(\frac{1}{2}, \frac{1}{2})$. That is to say if $p = \frac{1}{2}$, then our expression is an unbiased estimate of $p$, if $p > \frac{1}{2}$ our estimate is larger than $p$, for $p < \frac{1}{2}$ this estimate is smaller than $p$. Clearly for $p$ equals to one or zero, it is unbiased. Overall, our estimate has a strong ``overconfident" bias when $s$ and $t$ are neighbors.
\end{remark}

\begin{remark}
	Note although we are using the ``less than" sign when denoting $s <_{\pmb{P}_{st}} t$, it is technically not proper ordering. For example if we have $s <_{\pmb{P}_{st}} t$ and $t <_{\pmb{P}_{st}} r$, we do not necessarily have $s <_{\pmb{P}_{st}} r$. In fact any time we estimate the ordering from neighboring vertices, transitivity is lost.
\end{remark}

Results are presented below. 

\subsection{Results}





