\section{Literature Review}

Adjectives such as good, great, and excellent are similar in meaning but differ in intensity. Intensity ordering is useful in several NLP tasks, and in general defining any algebra over some subset of lexicon is an important first step in properly characterizing the semantics of a language. However this data is missing in most lexical resources such as dictionaries and WordNet. In this paper we present an unsupervised apporach that first pairwise rank adjectives by approximating their distribution around select liguistic-patterns, then resolve inconsistencies using an integer linear programming formulation. We test our approach on the English adjective clusters distributed by \newcite{demelo:13}, achieving $75.0\%$ pairwise accuracy without relying on annotator information as Bansal did. Most notably, we broke through the $0.60$ Kendall's tau barrier eluding previous research, thereby achieving near human-level performance under Kendall's tau and pairwise accuracy.

Linguistic scale is a set of words of the same grammatical category that can be ordered by their expressive strength or degree of informativeness \cite{sheinman2009adjscales}. Ranking adjectives over such a scale is a particularly important task in sentiment analysis, recognizing textual entailment, question answering, summarization, and automatic text understanding and generation. For instance, understanding the word ``great" is a stronger indicator of quality than the word ``good" could help refine the decision boundary between four star reviews versus five star one. However, current lexical resources such as WordNet do not provided such crucial information about the intensity order of adjectives.

Past work approached this problem in two ways: distributional and linguistic-pattern based. \newcite{kim2013deriving} showed that word vectors learned by a recurrent neural network language model can determine scalar relationships among adjectives. Specifically, given a line connecting a pair of antonyms, they posited that intermediate adjective word vectors extracted along this line should correspond to some intensity scale determined by the antonyms. The quality of the extracted relationship is evaluated using indirect yes/no question answer pairs, and they achieved 72.8\% pairwise accuracy over 125 pairs.

While distributional methods infer pairwise relationship between adjectives based on how they occur in the corpus separately, linguistic-pattern based approaches decides this relationship using their joint co-occurence around pre-determined patterns \cite{sheinman2009adjscales,schulam2010automatically,sheinman2012refining} . For example, the phrase ``good but not great" suggests good is less intense than great. These patterns are hand-curated for their precision and unsurprisingly enjoy high accuracy. However, they suffer from low recall because the amount of data needed to relate a pair of adjectives is exponential in length of the pattern, while such patterns are no less than four to five words long.

\newcite{demelo:13} addressed this data sparsity problem by exploiting the transitive property of partial orderings to determine unobserved pairwise relationships. They observed that in order to deduce an ordering over good, great, and excellent, it suffices to observe good is less than great, and great is less than excellent. Then by transitive property of the ordering we conclude good is also less than excellent. This fixed relationship among adjectives is enforced by a mixed integer linear program (MILP). Banal and de Melo tested their approach on 91 adjective clusters, where the average number of adjectives in each cluster is just over three, and each cluster is ranked by a set of annotators. They reported 69.6\% pair-wise accuracy and 0.57 average Kendall's tau. 

Bansal's method suffer from one major drawback, observe in the example above if we only observe an ordering between good and great, and good and execellent, then no conclusion can be made about the ordering between great and excellent. In general, in order to place an ordering over $n$ items, we need $n - 1$ ``critical" pairwise comparisons. This is a very restrictive assumption in practice, in fact most adjectives simply do not co-occur around the given set of patterns at all, thus no meaningful ordering may be placed. We combat the data sparsity problem in three ways. First, we extract additional linguistic pattern. Next we assume the phrases are generated in a Markov manner to approximate the probability of unseen phrases. Finally, we explore novel sources of data extracted from PPDB corpus. Once the data is prepared, we use a variety of inference methods to rank the adjectives, revealing the promises and limitations of each dataset and method.
